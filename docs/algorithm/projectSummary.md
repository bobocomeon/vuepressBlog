- 各位评委大家下午好，本次申请的是前端通道T5升T6
翻页
- 下面我将分别从个人介绍，项目经历，总结规划这三个方面来进行阐述。
翻页
- 我叫杨金海，来自前端研发组，18年6月毕业加入风控研发中心，主要负责催收相关的业务以及前端组内的公共开发工具建设，期间也参与了外呼模块，疫情催收移动端从0至1， 以及各类还款工具的重要项目，乐于技术创新和分享
翻页
- 下面我将从我的项目经历进行介绍
翻页
- 现在介绍的是 JS全埋点工具实现
这个项目产生的背景是，业务需要对系统里面的坐席进行一个原始数据的收集，比如查询的参数，按钮的添加，页面的pvuv等，将这些收集到的数据进行一个分析和统计，指定出合适的策略

我们在平时的开发当经常接到一些关于数据埋点的需求，这些都是量级比较小，可以针对特定的场景进行开发定制，来获得不同维度的消息，进行一个数据的上报，以此来达到数据分析的效果


这些的痛点就是，每次需要增加新的埋点都需要开发参与和迭代，而且业务代码高度耦合，不利于后期的维护和迭代，集团也封装了统一的埋点上报，暴露出很多方法不同维度的数据上报。























翻页
- 这个项目产生的背景是，催收业务方需对用户行为，通过数据埋点的方式得到一些原始数据，比如获取查询参数、提交的数据、用户操作轨迹，出勤度，将这些用户属性、行为属性转化为可视化图标，指定出合适的策略
扩展延伸
- 我们平时在开发当中也会接到一些埋点需求来进行不同维度的数据分析，这些都是量级相对小，可针对场景进行定制化开发，比如集团有统一的数据上报，获取很多维度的信息，暴露出很多业务接入的接口进行数据上报
翻页
- 在最开始技术选型的时候，针对用户的详情页面进行收集，作为系统最复杂含有信息量最多的页面，数据量会很大，除了一些通用数据上报之外还要支持自定义上报，于是就有了代码埋点和监听点击事件形成数据流上报这两种方案
翻页
- 代码埋点是在需要获得数据上报的地方增加代码埋点，适合对上下文理解要求高的业务数据，嵌套在业务代码中，我们在平时系统中加入的埋点就是这种方式，优点是可以按照业务的上报详细、定制化的数据，单缺点也很明显，维护成本高，每次迭代都需要开发参与，而且容易出错，和业务代码高度耦合，当业务想获得未埋点的数据时，是无法获得获得历史数据。
翻页
- 让一件事情需要重复操作，是不是可以想能不能有程序来替代人工自动完成。关于无痕埋点，尽可能按照程序制定的规则手机所有控件的操作数据，并采集所有属性上报。适用场景是上下文相对独立，通用的数据，优点是，维护成本低，后期迭代不需要开发参与，参数可配置，能获得历史数据，单缺点是数据传输和服务器大，无法收集上下文数据，数据筛选和分析增加了复杂度
翻页
- 针对以上背景和方案，就开发出了埋点上报第一期，通过指令将枚举好的数据加入元素节点，分析出事件的类型，页面变化形态，通过监听全局点击事件，获得标签属性数据判断是否需要上报，从下图中我们可以看到，用户产生的数据先存储在本地，每条数据有唯一的事件id、事件时间、事件类型等信息。
翻页
- 在做一期至上线后的过程中，也有一些痛点和反思，对现有系统的侵入还是存在，易造成未知错误，新系统开发还需要开发参与，（很快后面我们接到了二期迭代，委外系统的监控埋点以及额外页面的埋点包括一些自定义的数据上报），未能做到可配置化，低耦合，数据也并非全量，优点是数据上报详细，拿到业务想要的结果
扩展延伸
- 那我们能不能针对这些场景指定出一个，和系统低耦合，又有历史数据溯源，维护成本低，上报详细的埋点上报工具呢。
翻页
- 就有了现在的催收数据上报系统二期，我们来看一个简单的数据流图，从引入sdk初始化，触发元素，到数据处理，再到数据上报这一整串链路，都在底层脚本完成，只需要业务系统引用加载
翻页
- 抽象描述着一条数据链路，分为用户行为层，事件代理层，负责数据收集和过滤，数据处理层和数据访问层，生出唯一ID以及数据传输存储
翻页
- 在用户行为层，我们定义事件的类型，有点击，提交，弹窗的关闭，针对页面有进入，离开，暂停、激活，这一步是对事件的一个分类
翻页
- 在事件代理层，我们监听劫持了点击事件，表单事件，以及过滤一些无效事件，这一步是对数据的一个统一收集
翻页
- 在数据处理层，会判断是否满足监听条件，比如是否是在我们规则里面的事件，自定义属性优先收集，比如在标签上增加自定属性，会优先收集，这一步对生出唯一id很重要，判断敏感数据，对不需要上报的数据可进行添加特定的class类名，在数据处理会进行过滤，生成唯一id，是通过页面的路径+自定义属性+事件的类型，组装成一个唯一id
翻页
- 在数据访问层，在上层数据处理好的会存储在本地，另外会暴露接口提交自定义的数据进行存储，但是每个坐席每天会产生很多的数据，肯定不是点击一下传输一下，会占用带宽，对操作也造成影响，在提交到远程数据的时候，当数据达到50条或者操作上一次操作超过了5分钟，进行一次批量的数据提交，保证对用户是无感知
翻页
- 从上线到现在的一些效果是，可多维度的分析监控坐席地行为，来达到分析操作轨迹，根据分析埋点数据支撑多次坐席优化需求，之前催收精细化运行提升坐席操作，一些功能得带用到了这些数据的支撑，需求迭代从之前的平均3天工时直接降为了0，目前催收和委外两个系统接入，数据量千万级别，并稳定运行。
翻页
- 这是委外系统通过埋点数据分析不同维度的数据，每天会已报表的形式发送邮件给对应的业务人员。
翻页
- 后期计划是扩大使用场景，目前只是在催收的pc端，将来可扩展到其他业务系统或者移动端，生成热力图，